{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZDxiF0Oxjun"
   },
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WanOur-Hxjut"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\programdata\\anaconda3\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: opencv-python in c:\\programdata\\anaconda3\\lib\\site-packages (4.5.5.62)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: absl-py in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (1.20.3)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (3.19.4)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (4.5.5.64)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (3.4.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rKt0vGlXxjuw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.preview in file C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.0/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key mathtext.fallback_to_cm in file C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.0/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.jpeg_quality in file C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.0/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key keymap.all_axes in file C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.0/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_path in file C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.0/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_args in file C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.0/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7EhCXG4Axjuw"
   },
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmmFClMoxjux"
   },
   "source": [
    "# 1. Make Some Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "F3Y_WAmjxjux"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JaAfH5ydxjuz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.face_landmarks.landmark[0].visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ME7iWJxxju0"
   },
   "source": [
    "# 2. Capture Landmarks & Export to CSV\n",
    "<!--<img src=\"https://i.imgur.com/8bForKY.png\">-->\n",
    "<img src=\"https://i.imgur.com/AzKNp7A.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "XXeqdpNXxju0"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "iALGUCUAxju1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_coords = len(results.pose_landmarks.landmark)+len(results.face_landmarks.landmark)\n",
    "num_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "3y_CR85kxju2"
   },
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GLXbgEuvxju2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'x1',\n",
       " 'y1',\n",
       " 'z1',\n",
       " 'v1',\n",
       " 'x2',\n",
       " 'y2',\n",
       " 'z2',\n",
       " 'v2',\n",
       " 'x3',\n",
       " 'y3',\n",
       " 'z3',\n",
       " 'v3',\n",
       " 'x4',\n",
       " 'y4',\n",
       " 'z4',\n",
       " 'v4',\n",
       " 'x5',\n",
       " 'y5',\n",
       " 'z5',\n",
       " 'v5',\n",
       " 'x6',\n",
       " 'y6',\n",
       " 'z6',\n",
       " 'v6',\n",
       " 'x7',\n",
       " 'y7',\n",
       " 'z7',\n",
       " 'v7',\n",
       " 'x8',\n",
       " 'y8',\n",
       " 'z8',\n",
       " 'v8',\n",
       " 'x9',\n",
       " 'y9',\n",
       " 'z9',\n",
       " 'v9',\n",
       " 'x10',\n",
       " 'y10',\n",
       " 'z10',\n",
       " 'v10',\n",
       " 'x11',\n",
       " 'y11',\n",
       " 'z11',\n",
       " 'v11',\n",
       " 'x12',\n",
       " 'y12',\n",
       " 'z12',\n",
       " 'v12',\n",
       " 'x13',\n",
       " 'y13',\n",
       " 'z13',\n",
       " 'v13',\n",
       " 'x14',\n",
       " 'y14',\n",
       " 'z14',\n",
       " 'v14',\n",
       " 'x15',\n",
       " 'y15',\n",
       " 'z15',\n",
       " 'v15',\n",
       " 'x16',\n",
       " 'y16',\n",
       " 'z16',\n",
       " 'v16',\n",
       " 'x17',\n",
       " 'y17',\n",
       " 'z17',\n",
       " 'v17',\n",
       " 'x18',\n",
       " 'y18',\n",
       " 'z18',\n",
       " 'v18',\n",
       " 'x19',\n",
       " 'y19',\n",
       " 'z19',\n",
       " 'v19',\n",
       " 'x20',\n",
       " 'y20',\n",
       " 'z20',\n",
       " 'v20',\n",
       " 'x21',\n",
       " 'y21',\n",
       " 'z21',\n",
       " 'v21',\n",
       " 'x22',\n",
       " 'y22',\n",
       " 'z22',\n",
       " 'v22',\n",
       " 'x23',\n",
       " 'y23',\n",
       " 'z23',\n",
       " 'v23',\n",
       " 'x24',\n",
       " 'y24',\n",
       " 'z24',\n",
       " 'v24',\n",
       " 'x25',\n",
       " 'y25',\n",
       " 'z25',\n",
       " 'v25',\n",
       " 'x26',\n",
       " 'y26',\n",
       " 'z26',\n",
       " 'v26',\n",
       " 'x27',\n",
       " 'y27',\n",
       " 'z27',\n",
       " 'v27',\n",
       " 'x28',\n",
       " 'y28',\n",
       " 'z28',\n",
       " 'v28',\n",
       " 'x29',\n",
       " 'y29',\n",
       " 'z29',\n",
       " 'v29',\n",
       " 'x30',\n",
       " 'y30',\n",
       " 'z30',\n",
       " 'v30',\n",
       " 'x31',\n",
       " 'y31',\n",
       " 'z31',\n",
       " 'v31',\n",
       " 'x32',\n",
       " 'y32',\n",
       " 'z32',\n",
       " 'v32',\n",
       " 'x33',\n",
       " 'y33',\n",
       " 'z33',\n",
       " 'v33',\n",
       " 'x34',\n",
       " 'y34',\n",
       " 'z34',\n",
       " 'v34',\n",
       " 'x35',\n",
       " 'y35',\n",
       " 'z35',\n",
       " 'v35',\n",
       " 'x36',\n",
       " 'y36',\n",
       " 'z36',\n",
       " 'v36',\n",
       " 'x37',\n",
       " 'y37',\n",
       " 'z37',\n",
       " 'v37',\n",
       " 'x38',\n",
       " 'y38',\n",
       " 'z38',\n",
       " 'v38',\n",
       " 'x39',\n",
       " 'y39',\n",
       " 'z39',\n",
       " 'v39',\n",
       " 'x40',\n",
       " 'y40',\n",
       " 'z40',\n",
       " 'v40',\n",
       " 'x41',\n",
       " 'y41',\n",
       " 'z41',\n",
       " 'v41',\n",
       " 'x42',\n",
       " 'y42',\n",
       " 'z42',\n",
       " 'v42',\n",
       " 'x43',\n",
       " 'y43',\n",
       " 'z43',\n",
       " 'v43',\n",
       " 'x44',\n",
       " 'y44',\n",
       " 'z44',\n",
       " 'v44',\n",
       " 'x45',\n",
       " 'y45',\n",
       " 'z45',\n",
       " 'v45',\n",
       " 'x46',\n",
       " 'y46',\n",
       " 'z46',\n",
       " 'v46',\n",
       " 'x47',\n",
       " 'y47',\n",
       " 'z47',\n",
       " 'v47',\n",
       " 'x48',\n",
       " 'y48',\n",
       " 'z48',\n",
       " 'v48',\n",
       " 'x49',\n",
       " 'y49',\n",
       " 'z49',\n",
       " 'v49',\n",
       " 'x50',\n",
       " 'y50',\n",
       " 'z50',\n",
       " 'v50',\n",
       " 'x51',\n",
       " 'y51',\n",
       " 'z51',\n",
       " 'v51',\n",
       " 'x52',\n",
       " 'y52',\n",
       " 'z52',\n",
       " 'v52',\n",
       " 'x53',\n",
       " 'y53',\n",
       " 'z53',\n",
       " 'v53',\n",
       " 'x54',\n",
       " 'y54',\n",
       " 'z54',\n",
       " 'v54',\n",
       " 'x55',\n",
       " 'y55',\n",
       " 'z55',\n",
       " 'v55',\n",
       " 'x56',\n",
       " 'y56',\n",
       " 'z56',\n",
       " 'v56',\n",
       " 'x57',\n",
       " 'y57',\n",
       " 'z57',\n",
       " 'v57',\n",
       " 'x58',\n",
       " 'y58',\n",
       " 'z58',\n",
       " 'v58',\n",
       " 'x59',\n",
       " 'y59',\n",
       " 'z59',\n",
       " 'v59',\n",
       " 'x60',\n",
       " 'y60',\n",
       " 'z60',\n",
       " 'v60',\n",
       " 'x61',\n",
       " 'y61',\n",
       " 'z61',\n",
       " 'v61',\n",
       " 'x62',\n",
       " 'y62',\n",
       " 'z62',\n",
       " 'v62',\n",
       " 'x63',\n",
       " 'y63',\n",
       " 'z63',\n",
       " 'v63',\n",
       " 'x64',\n",
       " 'y64',\n",
       " 'z64',\n",
       " 'v64',\n",
       " 'x65',\n",
       " 'y65',\n",
       " 'z65',\n",
       " 'v65',\n",
       " 'x66',\n",
       " 'y66',\n",
       " 'z66',\n",
       " 'v66',\n",
       " 'x67',\n",
       " 'y67',\n",
       " 'z67',\n",
       " 'v67',\n",
       " 'x68',\n",
       " 'y68',\n",
       " 'z68',\n",
       " 'v68',\n",
       " 'x69',\n",
       " 'y69',\n",
       " 'z69',\n",
       " 'v69',\n",
       " 'x70',\n",
       " 'y70',\n",
       " 'z70',\n",
       " 'v70',\n",
       " 'x71',\n",
       " 'y71',\n",
       " 'z71',\n",
       " 'v71',\n",
       " 'x72',\n",
       " 'y72',\n",
       " 'z72',\n",
       " 'v72',\n",
       " 'x73',\n",
       " 'y73',\n",
       " 'z73',\n",
       " 'v73',\n",
       " 'x74',\n",
       " 'y74',\n",
       " 'z74',\n",
       " 'v74',\n",
       " 'x75',\n",
       " 'y75',\n",
       " 'z75',\n",
       " 'v75',\n",
       " 'x76',\n",
       " 'y76',\n",
       " 'z76',\n",
       " 'v76',\n",
       " 'x77',\n",
       " 'y77',\n",
       " 'z77',\n",
       " 'v77',\n",
       " 'x78',\n",
       " 'y78',\n",
       " 'z78',\n",
       " 'v78',\n",
       " 'x79',\n",
       " 'y79',\n",
       " 'z79',\n",
       " 'v79',\n",
       " 'x80',\n",
       " 'y80',\n",
       " 'z80',\n",
       " 'v80',\n",
       " 'x81',\n",
       " 'y81',\n",
       " 'z81',\n",
       " 'v81',\n",
       " 'x82',\n",
       " 'y82',\n",
       " 'z82',\n",
       " 'v82',\n",
       " 'x83',\n",
       " 'y83',\n",
       " 'z83',\n",
       " 'v83',\n",
       " 'x84',\n",
       " 'y84',\n",
       " 'z84',\n",
       " 'v84',\n",
       " 'x85',\n",
       " 'y85',\n",
       " 'z85',\n",
       " 'v85',\n",
       " 'x86',\n",
       " 'y86',\n",
       " 'z86',\n",
       " 'v86',\n",
       " 'x87',\n",
       " 'y87',\n",
       " 'z87',\n",
       " 'v87',\n",
       " 'x88',\n",
       " 'y88',\n",
       " 'z88',\n",
       " 'v88',\n",
       " 'x89',\n",
       " 'y89',\n",
       " 'z89',\n",
       " 'v89',\n",
       " 'x90',\n",
       " 'y90',\n",
       " 'z90',\n",
       " 'v90',\n",
       " 'x91',\n",
       " 'y91',\n",
       " 'z91',\n",
       " 'v91',\n",
       " 'x92',\n",
       " 'y92',\n",
       " 'z92',\n",
       " 'v92',\n",
       " 'x93',\n",
       " 'y93',\n",
       " 'z93',\n",
       " 'v93',\n",
       " 'x94',\n",
       " 'y94',\n",
       " 'z94',\n",
       " 'v94',\n",
       " 'x95',\n",
       " 'y95',\n",
       " 'z95',\n",
       " 'v95',\n",
       " 'x96',\n",
       " 'y96',\n",
       " 'z96',\n",
       " 'v96',\n",
       " 'x97',\n",
       " 'y97',\n",
       " 'z97',\n",
       " 'v97',\n",
       " 'x98',\n",
       " 'y98',\n",
       " 'z98',\n",
       " 'v98',\n",
       " 'x99',\n",
       " 'y99',\n",
       " 'z99',\n",
       " 'v99',\n",
       " 'x100',\n",
       " 'y100',\n",
       " 'z100',\n",
       " 'v100',\n",
       " 'x101',\n",
       " 'y101',\n",
       " 'z101',\n",
       " 'v101',\n",
       " 'x102',\n",
       " 'y102',\n",
       " 'z102',\n",
       " 'v102',\n",
       " 'x103',\n",
       " 'y103',\n",
       " 'z103',\n",
       " 'v103',\n",
       " 'x104',\n",
       " 'y104',\n",
       " 'z104',\n",
       " 'v104',\n",
       " 'x105',\n",
       " 'y105',\n",
       " 'z105',\n",
       " 'v105',\n",
       " 'x106',\n",
       " 'y106',\n",
       " 'z106',\n",
       " 'v106',\n",
       " 'x107',\n",
       " 'y107',\n",
       " 'z107',\n",
       " 'v107',\n",
       " 'x108',\n",
       " 'y108',\n",
       " 'z108',\n",
       " 'v108',\n",
       " 'x109',\n",
       " 'y109',\n",
       " 'z109',\n",
       " 'v109',\n",
       " 'x110',\n",
       " 'y110',\n",
       " 'z110',\n",
       " 'v110',\n",
       " 'x111',\n",
       " 'y111',\n",
       " 'z111',\n",
       " 'v111',\n",
       " 'x112',\n",
       " 'y112',\n",
       " 'z112',\n",
       " 'v112',\n",
       " 'x113',\n",
       " 'y113',\n",
       " 'z113',\n",
       " 'v113',\n",
       " 'x114',\n",
       " 'y114',\n",
       " 'z114',\n",
       " 'v114',\n",
       " 'x115',\n",
       " 'y115',\n",
       " 'z115',\n",
       " 'v115',\n",
       " 'x116',\n",
       " 'y116',\n",
       " 'z116',\n",
       " 'v116',\n",
       " 'x117',\n",
       " 'y117',\n",
       " 'z117',\n",
       " 'v117',\n",
       " 'x118',\n",
       " 'y118',\n",
       " 'z118',\n",
       " 'v118',\n",
       " 'x119',\n",
       " 'y119',\n",
       " 'z119',\n",
       " 'v119',\n",
       " 'x120',\n",
       " 'y120',\n",
       " 'z120',\n",
       " 'v120',\n",
       " 'x121',\n",
       " 'y121',\n",
       " 'z121',\n",
       " 'v121',\n",
       " 'x122',\n",
       " 'y122',\n",
       " 'z122',\n",
       " 'v122',\n",
       " 'x123',\n",
       " 'y123',\n",
       " 'z123',\n",
       " 'v123',\n",
       " 'x124',\n",
       " 'y124',\n",
       " 'z124',\n",
       " 'v124',\n",
       " 'x125',\n",
       " 'y125',\n",
       " 'z125',\n",
       " 'v125',\n",
       " 'x126',\n",
       " 'y126',\n",
       " 'z126',\n",
       " 'v126',\n",
       " 'x127',\n",
       " 'y127',\n",
       " 'z127',\n",
       " 'v127',\n",
       " 'x128',\n",
       " 'y128',\n",
       " 'z128',\n",
       " 'v128',\n",
       " 'x129',\n",
       " 'y129',\n",
       " 'z129',\n",
       " 'v129',\n",
       " 'x130',\n",
       " 'y130',\n",
       " 'z130',\n",
       " 'v130',\n",
       " 'x131',\n",
       " 'y131',\n",
       " 'z131',\n",
       " 'v131',\n",
       " 'x132',\n",
       " 'y132',\n",
       " 'z132',\n",
       " 'v132',\n",
       " 'x133',\n",
       " 'y133',\n",
       " 'z133',\n",
       " 'v133',\n",
       " 'x134',\n",
       " 'y134',\n",
       " 'z134',\n",
       " 'v134',\n",
       " 'x135',\n",
       " 'y135',\n",
       " 'z135',\n",
       " 'v135',\n",
       " 'x136',\n",
       " 'y136',\n",
       " 'z136',\n",
       " 'v136',\n",
       " 'x137',\n",
       " 'y137',\n",
       " 'z137',\n",
       " 'v137',\n",
       " 'x138',\n",
       " 'y138',\n",
       " 'z138',\n",
       " 'v138',\n",
       " 'x139',\n",
       " 'y139',\n",
       " 'z139',\n",
       " 'v139',\n",
       " 'x140',\n",
       " 'y140',\n",
       " 'z140',\n",
       " 'v140',\n",
       " 'x141',\n",
       " 'y141',\n",
       " 'z141',\n",
       " 'v141',\n",
       " 'x142',\n",
       " 'y142',\n",
       " 'z142',\n",
       " 'v142',\n",
       " 'x143',\n",
       " 'y143',\n",
       " 'z143',\n",
       " 'v143',\n",
       " 'x144',\n",
       " 'y144',\n",
       " 'z144',\n",
       " 'v144',\n",
       " 'x145',\n",
       " 'y145',\n",
       " 'z145',\n",
       " 'v145',\n",
       " 'x146',\n",
       " 'y146',\n",
       " 'z146',\n",
       " 'v146',\n",
       " 'x147',\n",
       " 'y147',\n",
       " 'z147',\n",
       " 'v147',\n",
       " 'x148',\n",
       " 'y148',\n",
       " 'z148',\n",
       " 'v148',\n",
       " 'x149',\n",
       " 'y149',\n",
       " 'z149',\n",
       " 'v149',\n",
       " 'x150',\n",
       " 'y150',\n",
       " 'z150',\n",
       " 'v150',\n",
       " 'x151',\n",
       " 'y151',\n",
       " 'z151',\n",
       " 'v151',\n",
       " 'x152',\n",
       " 'y152',\n",
       " 'z152',\n",
       " 'v152',\n",
       " 'x153',\n",
       " 'y153',\n",
       " 'z153',\n",
       " 'v153',\n",
       " 'x154',\n",
       " 'y154',\n",
       " 'z154',\n",
       " 'v154',\n",
       " 'x155',\n",
       " 'y155',\n",
       " 'z155',\n",
       " 'v155',\n",
       " 'x156',\n",
       " 'y156',\n",
       " 'z156',\n",
       " 'v156',\n",
       " 'x157',\n",
       " 'y157',\n",
       " 'z157',\n",
       " 'v157',\n",
       " 'x158',\n",
       " 'y158',\n",
       " 'z158',\n",
       " 'v158',\n",
       " 'x159',\n",
       " 'y159',\n",
       " 'z159',\n",
       " 'v159',\n",
       " 'x160',\n",
       " 'y160',\n",
       " 'z160',\n",
       " 'v160',\n",
       " 'x161',\n",
       " 'y161',\n",
       " 'z161',\n",
       " 'v161',\n",
       " 'x162',\n",
       " 'y162',\n",
       " 'z162',\n",
       " 'v162',\n",
       " 'x163',\n",
       " 'y163',\n",
       " 'z163',\n",
       " 'v163',\n",
       " 'x164',\n",
       " 'y164',\n",
       " 'z164',\n",
       " 'v164',\n",
       " 'x165',\n",
       " 'y165',\n",
       " 'z165',\n",
       " 'v165',\n",
       " 'x166',\n",
       " 'y166',\n",
       " 'z166',\n",
       " 'v166',\n",
       " 'x167',\n",
       " 'y167',\n",
       " 'z167',\n",
       " 'v167',\n",
       " 'x168',\n",
       " 'y168',\n",
       " 'z168',\n",
       " 'v168',\n",
       " 'x169',\n",
       " 'y169',\n",
       " 'z169',\n",
       " 'v169',\n",
       " 'x170',\n",
       " 'y170',\n",
       " 'z170',\n",
       " 'v170',\n",
       " 'x171',\n",
       " 'y171',\n",
       " 'z171',\n",
       " 'v171',\n",
       " 'x172',\n",
       " 'y172',\n",
       " 'z172',\n",
       " 'v172',\n",
       " 'x173',\n",
       " 'y173',\n",
       " 'z173',\n",
       " 'v173',\n",
       " 'x174',\n",
       " 'y174',\n",
       " 'z174',\n",
       " 'v174',\n",
       " 'x175',\n",
       " 'y175',\n",
       " 'z175',\n",
       " 'v175',\n",
       " 'x176',\n",
       " 'y176',\n",
       " 'z176',\n",
       " 'v176',\n",
       " 'x177',\n",
       " 'y177',\n",
       " 'z177',\n",
       " 'v177',\n",
       " 'x178',\n",
       " 'y178',\n",
       " 'z178',\n",
       " 'v178',\n",
       " 'x179',\n",
       " 'y179',\n",
       " 'z179',\n",
       " 'v179',\n",
       " 'x180',\n",
       " 'y180',\n",
       " 'z180',\n",
       " 'v180',\n",
       " 'x181',\n",
       " 'y181',\n",
       " 'z181',\n",
       " 'v181',\n",
       " 'x182',\n",
       " 'y182',\n",
       " 'z182',\n",
       " 'v182',\n",
       " 'x183',\n",
       " 'y183',\n",
       " 'z183',\n",
       " 'v183',\n",
       " 'x184',\n",
       " 'y184',\n",
       " 'z184',\n",
       " 'v184',\n",
       " 'x185',\n",
       " 'y185',\n",
       " 'z185',\n",
       " 'v185',\n",
       " 'x186',\n",
       " 'y186',\n",
       " 'z186',\n",
       " 'v186',\n",
       " 'x187',\n",
       " 'y187',\n",
       " 'z187',\n",
       " 'v187',\n",
       " 'x188',\n",
       " 'y188',\n",
       " 'z188',\n",
       " 'v188',\n",
       " 'x189',\n",
       " 'y189',\n",
       " 'z189',\n",
       " 'v189',\n",
       " 'x190',\n",
       " 'y190',\n",
       " 'z190',\n",
       " 'v190',\n",
       " 'x191',\n",
       " 'y191',\n",
       " 'z191',\n",
       " 'v191',\n",
       " 'x192',\n",
       " 'y192',\n",
       " 'z192',\n",
       " 'v192',\n",
       " 'x193',\n",
       " 'y193',\n",
       " 'z193',\n",
       " 'v193',\n",
       " 'x194',\n",
       " 'y194',\n",
       " 'z194',\n",
       " 'v194',\n",
       " 'x195',\n",
       " 'y195',\n",
       " 'z195',\n",
       " 'v195',\n",
       " 'x196',\n",
       " 'y196',\n",
       " 'z196',\n",
       " 'v196',\n",
       " 'x197',\n",
       " 'y197',\n",
       " 'z197',\n",
       " 'v197',\n",
       " 'x198',\n",
       " 'y198',\n",
       " 'z198',\n",
       " 'v198',\n",
       " 'x199',\n",
       " 'y199',\n",
       " 'z199',\n",
       " 'v199',\n",
       " 'x200',\n",
       " 'y200',\n",
       " 'z200',\n",
       " 'v200',\n",
       " 'x201',\n",
       " 'y201',\n",
       " 'z201',\n",
       " 'v201',\n",
       " 'x202',\n",
       " 'y202',\n",
       " 'z202',\n",
       " 'v202',\n",
       " 'x203',\n",
       " 'y203',\n",
       " 'z203',\n",
       " 'v203',\n",
       " 'x204',\n",
       " 'y204',\n",
       " 'z204',\n",
       " 'v204',\n",
       " 'x205',\n",
       " 'y205',\n",
       " 'z205',\n",
       " 'v205',\n",
       " 'x206',\n",
       " 'y206',\n",
       " 'z206',\n",
       " 'v206',\n",
       " 'x207',\n",
       " 'y207',\n",
       " 'z207',\n",
       " 'v207',\n",
       " 'x208',\n",
       " 'y208',\n",
       " 'z208',\n",
       " 'v208',\n",
       " 'x209',\n",
       " 'y209',\n",
       " 'z209',\n",
       " 'v209',\n",
       " 'x210',\n",
       " 'y210',\n",
       " 'z210',\n",
       " 'v210',\n",
       " 'x211',\n",
       " 'y211',\n",
       " 'z211',\n",
       " 'v211',\n",
       " 'x212',\n",
       " 'y212',\n",
       " 'z212',\n",
       " 'v212',\n",
       " 'x213',\n",
       " 'y213',\n",
       " 'z213',\n",
       " 'v213',\n",
       " 'x214',\n",
       " 'y214',\n",
       " 'z214',\n",
       " 'v214',\n",
       " 'x215',\n",
       " 'y215',\n",
       " 'z215',\n",
       " 'v215',\n",
       " 'x216',\n",
       " 'y216',\n",
       " 'z216',\n",
       " 'v216',\n",
       " 'x217',\n",
       " 'y217',\n",
       " 'z217',\n",
       " 'v217',\n",
       " 'x218',\n",
       " 'y218',\n",
       " 'z218',\n",
       " 'v218',\n",
       " 'x219',\n",
       " 'y219',\n",
       " 'z219',\n",
       " 'v219',\n",
       " 'x220',\n",
       " 'y220',\n",
       " 'z220',\n",
       " 'v220',\n",
       " 'x221',\n",
       " 'y221',\n",
       " 'z221',\n",
       " 'v221',\n",
       " 'x222',\n",
       " 'y222',\n",
       " 'z222',\n",
       " 'v222',\n",
       " 'x223',\n",
       " 'y223',\n",
       " 'z223',\n",
       " 'v223',\n",
       " 'x224',\n",
       " 'y224',\n",
       " 'z224',\n",
       " 'v224',\n",
       " 'x225',\n",
       " 'y225',\n",
       " 'z225',\n",
       " 'v225',\n",
       " 'x226',\n",
       " 'y226',\n",
       " 'z226',\n",
       " 'v226',\n",
       " 'x227',\n",
       " 'y227',\n",
       " 'z227',\n",
       " 'v227',\n",
       " 'x228',\n",
       " 'y228',\n",
       " 'z228',\n",
       " 'v228',\n",
       " 'x229',\n",
       " 'y229',\n",
       " 'z229',\n",
       " 'v229',\n",
       " 'x230',\n",
       " 'y230',\n",
       " 'z230',\n",
       " 'v230',\n",
       " 'x231',\n",
       " 'y231',\n",
       " 'z231',\n",
       " 'v231',\n",
       " 'x232',\n",
       " 'y232',\n",
       " 'z232',\n",
       " 'v232',\n",
       " 'x233',\n",
       " 'y233',\n",
       " 'z233',\n",
       " 'v233',\n",
       " 'x234',\n",
       " 'y234',\n",
       " 'z234',\n",
       " 'v234',\n",
       " 'x235',\n",
       " 'y235',\n",
       " 'z235',\n",
       " 'v235',\n",
       " 'x236',\n",
       " 'y236',\n",
       " 'z236',\n",
       " 'v236',\n",
       " 'x237',\n",
       " 'y237',\n",
       " 'z237',\n",
       " 'v237',\n",
       " 'x238',\n",
       " 'y238',\n",
       " 'z238',\n",
       " 'v238',\n",
       " 'x239',\n",
       " 'y239',\n",
       " 'z239',\n",
       " 'v239',\n",
       " 'x240',\n",
       " 'y240',\n",
       " 'z240',\n",
       " 'v240',\n",
       " 'x241',\n",
       " 'y241',\n",
       " 'z241',\n",
       " 'v241',\n",
       " 'x242',\n",
       " 'y242',\n",
       " 'z242',\n",
       " 'v242',\n",
       " 'x243',\n",
       " 'y243',\n",
       " 'z243',\n",
       " 'v243',\n",
       " 'x244',\n",
       " 'y244',\n",
       " 'z244',\n",
       " 'v244',\n",
       " 'x245',\n",
       " 'y245',\n",
       " 'z245',\n",
       " 'v245',\n",
       " 'x246',\n",
       " 'y246',\n",
       " 'z246',\n",
       " 'v246',\n",
       " 'x247',\n",
       " 'y247',\n",
       " 'z247',\n",
       " 'v247',\n",
       " 'x248',\n",
       " 'y248',\n",
       " 'z248',\n",
       " 'v248',\n",
       " 'x249',\n",
       " 'y249',\n",
       " 'z249',\n",
       " 'v249',\n",
       " 'x250',\n",
       " 'y250',\n",
       " 'z250',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OmBab2EBxju3"
   },
   "outputs": [],
   "source": [
    "with open('coords.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "eq8AZBB1xju3"
   },
   "outputs": [],
   "source": [
    "class_name = \"Normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "T5y1Nao8xju4"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "            # Append class name \n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            # Export to CSV\n",
    "            with open('coords.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row) \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"Fatigue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "            # Append class name \n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            # Export to CSV\n",
    "            with open('coords.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row) \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"Anxiety\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "            # Append class name \n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            # Export to CSV\n",
    "            with open('coords.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row) \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"Angry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "            # Append class name \n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            # Export to CSV\n",
    "            with open('coords.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row) \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkdRztvxxju4"
   },
   "source": [
    "# 3. Train Custom Model Using Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPeFsfmWxju5"
   },
   "source": [
    "## 3.1 Read in Collected Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_j-zbn0Cxju5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "7wi5SSbyxju5"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "naRNr4gIxju5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.519015</td>\n",
       "      <td>0.709711</td>\n",
       "      <td>-0.873736</td>\n",
       "      <td>0.999543</td>\n",
       "      <td>0.562548</td>\n",
       "      <td>0.628961</td>\n",
       "      <td>-0.875275</td>\n",
       "      <td>0.998818</td>\n",
       "      <td>0.587117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042088</td>\n",
       "      <td>0</td>\n",
       "      <td>0.616321</td>\n",
       "      <td>0.633365</td>\n",
       "      <td>-0.017780</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624297</td>\n",
       "      <td>0.624521</td>\n",
       "      <td>-0.017874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.518136</td>\n",
       "      <td>0.673005</td>\n",
       "      <td>-0.897379</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>0.560578</td>\n",
       "      <td>0.597451</td>\n",
       "      <td>-0.888712</td>\n",
       "      <td>0.998919</td>\n",
       "      <td>0.584675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024727</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611566</td>\n",
       "      <td>0.577311</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618045</td>\n",
       "      <td>0.571050</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.514587</td>\n",
       "      <td>0.616093</td>\n",
       "      <td>-0.842586</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.555625</td>\n",
       "      <td>0.543377</td>\n",
       "      <td>-0.821337</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>0.578807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014664</td>\n",
       "      <td>0</td>\n",
       "      <td>0.601421</td>\n",
       "      <td>0.528039</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607863</td>\n",
       "      <td>0.524923</td>\n",
       "      <td>0.011844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.514153</td>\n",
       "      <td>0.588563</td>\n",
       "      <td>-0.847342</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.554745</td>\n",
       "      <td>0.518093</td>\n",
       "      <td>-0.826340</td>\n",
       "      <td>0.999098</td>\n",
       "      <td>0.577614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012216</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604919</td>\n",
       "      <td>0.514460</td>\n",
       "      <td>0.013796</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611083</td>\n",
       "      <td>0.512425</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.514170</td>\n",
       "      <td>0.576236</td>\n",
       "      <td>-0.814643</td>\n",
       "      <td>0.999682</td>\n",
       "      <td>0.554615</td>\n",
       "      <td>0.505182</td>\n",
       "      <td>-0.784966</td>\n",
       "      <td>0.999177</td>\n",
       "      <td>0.577188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008579</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607744</td>\n",
       "      <td>0.506996</td>\n",
       "      <td>0.017951</td>\n",
       "      <td>0</td>\n",
       "      <td>0.613933</td>\n",
       "      <td>0.504465</td>\n",
       "      <td>0.018544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class        x1        y1        z1        v1        x2        y2  \\\n",
       "0  Happy  0.519015  0.709711 -0.873736  0.999543  0.562548  0.628961   \n",
       "1  Happy  0.518136  0.673005 -0.897379  0.999582  0.560578  0.597451   \n",
       "2  Happy  0.514587  0.616093 -0.842586  0.999618  0.555625  0.543377   \n",
       "3  Happy  0.514153  0.588563 -0.847342  0.999652  0.554745  0.518093   \n",
       "4  Happy  0.514170  0.576236 -0.814643  0.999682  0.554615  0.505182   \n",
       "\n",
       "         z2        v2        x3  ...      z499  v499      x500      y500  \\\n",
       "0 -0.875275  0.998818  0.587117  ... -0.042088     0  0.616321  0.633365   \n",
       "1 -0.888712  0.998919  0.584675  ... -0.024727     0  0.611566  0.577311   \n",
       "2 -0.821337  0.999009  0.578807  ... -0.014664     0  0.601421  0.528039   \n",
       "3 -0.826340  0.999098  0.577614  ... -0.012216     0  0.604919  0.514460   \n",
       "4 -0.784966  0.999177  0.577188  ... -0.008579     0  0.607744  0.506996   \n",
       "\n",
       "       z500  v500      x501      y501      z501  v501  \n",
       "0 -0.017780     0  0.624297  0.624521 -0.017874     0  \n",
       "1  0.001688     0  0.618045  0.571050  0.002021     0  \n",
       "2  0.011426     0  0.607863  0.524923  0.011844     0  \n",
       "3  0.013796     0  0.611083  0.512425  0.014218     0  \n",
       "4  0.017951     0  0.613933  0.504465  0.018544     0  \n",
       "\n",
       "[5 rows x 2005 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "1NjAhuuKxju6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>Angry</td>\n",
       "      <td>0.520437</td>\n",
       "      <td>0.465284</td>\n",
       "      <td>-0.367676</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.547221</td>\n",
       "      <td>0.427252</td>\n",
       "      <td>-0.299362</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.560491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005844</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571175</td>\n",
       "      <td>0.446963</td>\n",
       "      <td>0.021185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.576125</td>\n",
       "      <td>0.442927</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>Angry</td>\n",
       "      <td>0.520338</td>\n",
       "      <td>0.465969</td>\n",
       "      <td>-0.418594</td>\n",
       "      <td>0.999495</td>\n",
       "      <td>0.546949</td>\n",
       "      <td>0.427647</td>\n",
       "      <td>-0.344232</td>\n",
       "      <td>0.999051</td>\n",
       "      <td>0.560239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569815</td>\n",
       "      <td>0.450470</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>0</td>\n",
       "      <td>0.574486</td>\n",
       "      <td>0.447058</td>\n",
       "      <td>0.020738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>Angry</td>\n",
       "      <td>0.520085</td>\n",
       "      <td>0.466898</td>\n",
       "      <td>-0.473887</td>\n",
       "      <td>0.999462</td>\n",
       "      <td>0.545111</td>\n",
       "      <td>0.428245</td>\n",
       "      <td>-0.404624</td>\n",
       "      <td>0.998930</td>\n",
       "      <td>0.558175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>0</td>\n",
       "      <td>0.567147</td>\n",
       "      <td>0.446311</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571693</td>\n",
       "      <td>0.442837</td>\n",
       "      <td>0.019732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>Angry</td>\n",
       "      <td>0.520053</td>\n",
       "      <td>0.467071</td>\n",
       "      <td>-0.441177</td>\n",
       "      <td>0.999456</td>\n",
       "      <td>0.544153</td>\n",
       "      <td>0.428593</td>\n",
       "      <td>-0.375526</td>\n",
       "      <td>0.998860</td>\n",
       "      <td>0.557023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>0</td>\n",
       "      <td>0.570375</td>\n",
       "      <td>0.446093</td>\n",
       "      <td>0.019240</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575051</td>\n",
       "      <td>0.442501</td>\n",
       "      <td>0.019886</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>Angry</td>\n",
       "      <td>0.521677</td>\n",
       "      <td>0.459457</td>\n",
       "      <td>-0.342312</td>\n",
       "      <td>0.999502</td>\n",
       "      <td>0.544469</td>\n",
       "      <td>0.424694</td>\n",
       "      <td>-0.279833</td>\n",
       "      <td>0.998943</td>\n",
       "      <td>0.557050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006753</td>\n",
       "      <td>0</td>\n",
       "      <td>0.576301</td>\n",
       "      <td>0.441015</td>\n",
       "      <td>0.020348</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581250</td>\n",
       "      <td>0.437223</td>\n",
       "      <td>0.021132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class        x1        y1        z1        v1        x2        y2  \\\n",
       "1021  Angry  0.520437  0.465284 -0.367676  0.999500  0.547221  0.427252   \n",
       "1022  Angry  0.520338  0.465969 -0.418594  0.999495  0.546949  0.427647   \n",
       "1023  Angry  0.520085  0.466898 -0.473887  0.999462  0.545111  0.428245   \n",
       "1024  Angry  0.520053  0.467071 -0.441177  0.999456  0.544153  0.428593   \n",
       "1025  Angry  0.521677  0.459457 -0.342312  0.999502  0.544469  0.424694   \n",
       "\n",
       "            z2        v2        x3  ...      z499  v499      x500      y500  \\\n",
       "1021 -0.299362  0.999077  0.560491  ...  0.005844     0  0.571175  0.446963   \n",
       "1022 -0.344232  0.999051  0.560239  ...  0.004595     0  0.569815  0.450470   \n",
       "1023 -0.404624  0.998930  0.558175  ...  0.004736     0  0.567147  0.446311   \n",
       "1024 -0.375526  0.998860  0.557023  ...  0.005451     0  0.570375  0.446093   \n",
       "1025 -0.279833  0.998943  0.557050  ...  0.006753     0  0.576301  0.441015   \n",
       "\n",
       "          z500  v500      x501      y501      z501  v501  \n",
       "1021  0.021185     0  0.576125  0.442927  0.022044     0  \n",
       "1022  0.020036     0  0.574486  0.447058  0.020738     0  \n",
       "1023  0.019050     0  0.571693  0.442837  0.019732     0  \n",
       "1024  0.019240     0  0.575051  0.442501  0.019886     0  \n",
       "1025  0.020348     0  0.581250  0.437223  0.021132     0  \n",
       "\n",
       "[5 rows x 2005 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "2O-TRhA_xju6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Fatigue</td>\n",
       "      <td>0.501353</td>\n",
       "      <td>0.440425</td>\n",
       "      <td>-1.559479</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.546145</td>\n",
       "      <td>0.334306</td>\n",
       "      <td>-1.493340</td>\n",
       "      <td>0.999808</td>\n",
       "      <td>0.575042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018265</td>\n",
       "      <td>0</td>\n",
       "      <td>0.620728</td>\n",
       "      <td>0.331190</td>\n",
       "      <td>0.015991</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627805</td>\n",
       "      <td>0.325714</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>Fatigue</td>\n",
       "      <td>0.507899</td>\n",
       "      <td>0.438950</td>\n",
       "      <td>-1.831014</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.550133</td>\n",
       "      <td>0.331567</td>\n",
       "      <td>-1.776768</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>0.577757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020021</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624359</td>\n",
       "      <td>0.330938</td>\n",
       "      <td>0.013583</td>\n",
       "      <td>0</td>\n",
       "      <td>0.631056</td>\n",
       "      <td>0.326816</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Fatigue</td>\n",
       "      <td>0.510101</td>\n",
       "      <td>0.438685</td>\n",
       "      <td>-1.957784</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.551578</td>\n",
       "      <td>0.331469</td>\n",
       "      <td>-1.896073</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.578512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018904</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624886</td>\n",
       "      <td>0.334274</td>\n",
       "      <td>0.015217</td>\n",
       "      <td>0</td>\n",
       "      <td>0.631798</td>\n",
       "      <td>0.329963</td>\n",
       "      <td>0.015691</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>Fatigue</td>\n",
       "      <td>0.512583</td>\n",
       "      <td>0.438808</td>\n",
       "      <td>-2.043802</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.553650</td>\n",
       "      <td>0.331500</td>\n",
       "      <td>-1.984129</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.580033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019676</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625287</td>\n",
       "      <td>0.336206</td>\n",
       "      <td>0.013843</td>\n",
       "      <td>0</td>\n",
       "      <td>0.632178</td>\n",
       "      <td>0.331602</td>\n",
       "      <td>0.014340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>Fatigue</td>\n",
       "      <td>0.513564</td>\n",
       "      <td>0.438464</td>\n",
       "      <td>-1.928813</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.555251</td>\n",
       "      <td>0.331498</td>\n",
       "      <td>-1.869137</td>\n",
       "      <td>0.999762</td>\n",
       "      <td>0.581427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018299</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625506</td>\n",
       "      <td>0.336715</td>\n",
       "      <td>0.014638</td>\n",
       "      <td>0</td>\n",
       "      <td>0.632582</td>\n",
       "      <td>0.332213</td>\n",
       "      <td>0.015097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>Fatigue</td>\n",
       "      <td>0.587731</td>\n",
       "      <td>0.190552</td>\n",
       "      <td>-1.861672</td>\n",
       "      <td>0.974269</td>\n",
       "      <td>0.630693</td>\n",
       "      <td>0.115152</td>\n",
       "      <td>-1.855994</td>\n",
       "      <td>0.988167</td>\n",
       "      <td>0.654528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016724</td>\n",
       "      <td>0</td>\n",
       "      <td>0.713078</td>\n",
       "      <td>0.055194</td>\n",
       "      <td>0.024754</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720354</td>\n",
       "      <td>0.047327</td>\n",
       "      <td>0.026135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>Fatigue</td>\n",
       "      <td>0.586964</td>\n",
       "      <td>0.191868</td>\n",
       "      <td>-1.832418</td>\n",
       "      <td>0.976748</td>\n",
       "      <td>0.630195</td>\n",
       "      <td>0.114448</td>\n",
       "      <td>-1.833076</td>\n",
       "      <td>0.989088</td>\n",
       "      <td>0.653950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017740</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712860</td>\n",
       "      <td>0.054254</td>\n",
       "      <td>0.022487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720145</td>\n",
       "      <td>0.046009</td>\n",
       "      <td>0.023816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>Fatigue</td>\n",
       "      <td>0.587990</td>\n",
       "      <td>0.193676</td>\n",
       "      <td>-1.969235</td>\n",
       "      <td>0.979053</td>\n",
       "      <td>0.630475</td>\n",
       "      <td>0.115751</td>\n",
       "      <td>-1.937167</td>\n",
       "      <td>0.990128</td>\n",
       "      <td>0.654077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015541</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706913</td>\n",
       "      <td>0.053524</td>\n",
       "      <td>0.026996</td>\n",
       "      <td>0</td>\n",
       "      <td>0.713999</td>\n",
       "      <td>0.045798</td>\n",
       "      <td>0.028545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>Fatigue</td>\n",
       "      <td>0.587226</td>\n",
       "      <td>0.192322</td>\n",
       "      <td>-2.000540</td>\n",
       "      <td>0.981092</td>\n",
       "      <td>0.629701</td>\n",
       "      <td>0.114358</td>\n",
       "      <td>-1.985934</td>\n",
       "      <td>0.990953</td>\n",
       "      <td>0.653167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011823</td>\n",
       "      <td>0</td>\n",
       "      <td>0.699747</td>\n",
       "      <td>0.054081</td>\n",
       "      <td>0.028421</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706786</td>\n",
       "      <td>0.046849</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>Fatigue</td>\n",
       "      <td>0.585273</td>\n",
       "      <td>0.193387</td>\n",
       "      <td>-1.875240</td>\n",
       "      <td>0.982841</td>\n",
       "      <td>0.627427</td>\n",
       "      <td>0.115195</td>\n",
       "      <td>-1.871652</td>\n",
       "      <td>0.991466</td>\n",
       "      <td>0.651331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012708</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700429</td>\n",
       "      <td>0.044666</td>\n",
       "      <td>0.027691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707510</td>\n",
       "      <td>0.037787</td>\n",
       "      <td>0.029059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class        x1        y1        z1        v1        x2        y2  \\\n",
       "406  Fatigue  0.501353  0.440425 -1.559479  0.999919  0.546145  0.334306   \n",
       "407  Fatigue  0.507899  0.438950 -1.831014  0.999918  0.550133  0.331567   \n",
       "408  Fatigue  0.510101  0.438685 -1.957784  0.999909  0.551578  0.331469   \n",
       "409  Fatigue  0.512583  0.438808 -2.043802  0.999909  0.553650  0.331500   \n",
       "410  Fatigue  0.513564  0.438464 -1.928813  0.999904  0.555251  0.331498   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "562  Fatigue  0.587731  0.190552 -1.861672  0.974269  0.630693  0.115152   \n",
       "563  Fatigue  0.586964  0.191868 -1.832418  0.976748  0.630195  0.114448   \n",
       "564  Fatigue  0.587990  0.193676 -1.969235  0.979053  0.630475  0.115751   \n",
       "565  Fatigue  0.587226  0.192322 -2.000540  0.981092  0.629701  0.114358   \n",
       "566  Fatigue  0.585273  0.193387 -1.875240  0.982841  0.627427  0.115195   \n",
       "\n",
       "           z2        v2        x3  ...      z499  v499      x500      y500  \\\n",
       "406 -1.493340  0.999808  0.575042  ... -0.018265     0  0.620728  0.331190   \n",
       "407 -1.776768  0.999802  0.577757  ... -0.020021     0  0.624359  0.330938   \n",
       "408 -1.896073  0.999777  0.578512  ... -0.018904     0  0.624886  0.334274   \n",
       "409 -1.984129  0.999778  0.580033  ... -0.019676     0  0.625287  0.336206   \n",
       "410 -1.869137  0.999762  0.581427  ... -0.018299     0  0.625506  0.336715   \n",
       "..        ...       ...       ...  ...       ...   ...       ...       ...   \n",
       "562 -1.855994  0.988167  0.654528  ... -0.016724     0  0.713078  0.055194   \n",
       "563 -1.833076  0.989088  0.653950  ... -0.017740     0  0.712860  0.054254   \n",
       "564 -1.937167  0.990128  0.654077  ... -0.015541     0  0.706913  0.053524   \n",
       "565 -1.985934  0.990953  0.653167  ... -0.011823     0  0.699747  0.054081   \n",
       "566 -1.871652  0.991466  0.651331  ... -0.012708     0  0.700429  0.044666   \n",
       "\n",
       "         z500  v500      x501      y501      z501  v501  \n",
       "406  0.015991     0  0.627805  0.325714  0.016575     0  \n",
       "407  0.013583     0  0.631056  0.326816  0.013924     0  \n",
       "408  0.015217     0  0.631798  0.329963  0.015691     0  \n",
       "409  0.013843     0  0.632178  0.331602  0.014340     0  \n",
       "410  0.014638     0  0.632582  0.332213  0.015097     0  \n",
       "..        ...   ...       ...       ...       ...   ...  \n",
       "562  0.024754     0  0.720354  0.047327  0.026135     0  \n",
       "563  0.022487     0  0.720145  0.046009  0.023816     0  \n",
       "564  0.026996     0  0.713999  0.045798  0.028545     0  \n",
       "565  0.028421     0  0.706786  0.046849  0.029907     0  \n",
       "566  0.027691     0  0.707510  0.037787  0.029059     0  \n",
       "\n",
       "[161 rows x 2005 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['class']=='Fatigue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "jDBKhznDxju6"
   },
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1) # features\n",
    "y = df['class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "tXZBbl6wxju7"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "FWF4phqqxju7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "803    Anxiety\n",
       "523    Fatigue\n",
       "89       Happy\n",
       "916      Angry\n",
       "270     Normal\n",
       "        ...   \n",
       "499    Fatigue\n",
       "44       Happy\n",
       "968      Angry\n",
       "504    Fatigue\n",
       "187      Happy\n",
       "Name: class, Length: 308, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHkvvUi_xju7"
   },
   "source": [
    "## 3.2 Train Machine Learning Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "dioClwg_xju7"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "S779kSi-xju7"
   },
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "jf6hl_T-xju8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "rPpNMW6yxju8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Y5AZcS4bxju8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Anxiety', 'Fatigue', 'Happy', 'Angry', 'Normal', 'Normal',\n",
       "       'Happy', 'Angry', 'Anxiety', 'Happy', 'Fatigue', 'Anxiety',\n",
       "       'Fatigue', 'Normal', 'Fatigue', 'Anxiety', 'Angry', 'Anxiety',\n",
       "       'Normal', 'Angry', 'Fatigue', 'Anxiety', 'Normal', 'Angry',\n",
       "       'Normal', 'Fatigue', 'Anxiety', 'Anxiety', 'Fatigue', 'Happy',\n",
       "       'Normal', 'Anxiety', 'Normal', 'Anxiety', 'Fatigue', 'Fatigue',\n",
       "       'Happy', 'Fatigue', 'Anxiety', 'Anxiety', 'Happy', 'Normal',\n",
       "       'Angry', 'Fatigue', 'Happy', 'Happy', 'Normal', 'Normal',\n",
       "       'Fatigue', 'Normal', 'Fatigue', 'Anxiety', 'Normal', 'Happy',\n",
       "       'Normal', 'Happy', 'Normal', 'Happy', 'Normal', 'Anxiety',\n",
       "       'Normal', 'Normal', 'Happy', 'Anxiety', 'Anxiety', 'Anxiety',\n",
       "       'Angry', 'Happy', 'Angry', 'Normal', 'Fatigue', 'Angry', 'Happy',\n",
       "       'Anxiety', 'Anxiety', 'Anxiety', 'Happy', 'Normal', 'Happy',\n",
       "       'Angry', 'Normal', 'Normal', 'Angry', 'Happy', 'Normal', 'Happy',\n",
       "       'Fatigue', 'Normal', 'Normal', 'Normal', 'Normal', 'Anxiety',\n",
       "       'Angry', 'Fatigue', 'Fatigue', 'Anxiety', 'Anxiety', 'Normal',\n",
       "       'Anxiety', 'Anxiety', 'Anxiety', 'Normal', 'Anxiety', 'Normal',\n",
       "       'Angry', 'Happy', 'Anxiety', 'Fatigue', 'Anxiety', 'Anxiety',\n",
       "       'Angry', 'Fatigue', 'Normal', 'Anxiety', 'Anxiety', 'Anxiety',\n",
       "       'Anxiety', 'Happy', 'Angry', 'Happy', 'Anxiety', 'Angry',\n",
       "       'Fatigue', 'Anxiety', 'Anxiety', 'Happy', 'Happy', 'Fatigue',\n",
       "       'Angry', 'Angry', 'Anxiety', 'Normal', 'Normal', 'Happy',\n",
       "       'Fatigue', 'Fatigue', 'Fatigue', 'Angry', 'Happy', 'Fatigue',\n",
       "       'Angry', 'Anxiety', 'Fatigue', 'Happy', 'Angry', 'Anxiety',\n",
       "       'Normal', 'Fatigue', 'Normal', 'Anxiety', 'Anxiety', 'Happy',\n",
       "       'Happy', 'Angry', 'Angry', 'Anxiety', 'Angry', 'Happy', 'Anxiety',\n",
       "       'Anxiety', 'Happy', 'Angry', 'Happy', 'Happy', 'Angry', 'Angry',\n",
       "       'Happy', 'Anxiety', 'Fatigue', 'Normal', 'Anxiety', 'Normal',\n",
       "       'Normal', 'Angry', 'Fatigue', 'Happy', 'Happy', 'Normal',\n",
       "       'Anxiety', 'Angry', 'Anxiety', 'Angry', 'Anxiety', 'Happy',\n",
       "       'Anxiety', 'Anxiety', 'Fatigue', 'Normal', 'Angry', 'Anxiety',\n",
       "       'Normal', 'Normal', 'Anxiety', 'Anxiety', 'Angry', 'Fatigue',\n",
       "       'Fatigue', 'Fatigue', 'Angry', 'Happy', 'Normal', 'Fatigue',\n",
       "       'Normal', 'Angry', 'Anxiety', 'Fatigue', 'Normal', 'Normal',\n",
       "       'Happy', 'Anxiety', 'Happy', 'Normal', 'Angry', 'Fatigue',\n",
       "       'Fatigue', 'Happy', 'Fatigue', 'Anxiety', 'Happy', 'Happy',\n",
       "       'Angry', 'Normal', 'Happy', 'Normal', 'Happy', 'Angry', 'Anxiety',\n",
       "       'Normal', 'Happy', 'Normal', 'Angry', 'Fatigue', 'Normal', 'Angry',\n",
       "       'Fatigue', 'Fatigue', 'Anxiety', 'Anxiety', 'Normal', 'Anxiety',\n",
       "       'Normal', 'Angry', 'Fatigue', 'Angry', 'Happy', 'Normal',\n",
       "       'Anxiety', 'Happy', 'Fatigue', 'Normal', 'Fatigue', 'Angry',\n",
       "       'Normal', 'Happy', 'Fatigue', 'Normal', 'Fatigue', 'Normal',\n",
       "       'Normal', 'Happy', 'Fatigue', 'Anxiety', 'Anxiety', 'Fatigue',\n",
       "       'Fatigue', 'Anxiety', 'Happy', 'Normal', 'Anxiety', 'Happy',\n",
       "       'Happy', 'Fatigue', 'Happy', 'Happy', 'Normal', 'Normal',\n",
       "       'Fatigue', 'Anxiety', 'Normal', 'Angry', 'Anxiety', 'Fatigue',\n",
       "       'Angry', 'Happy', 'Anxiety', 'Happy', 'Happy', 'Normal', 'Happy',\n",
       "       'Happy', 'Angry', 'Normal', 'Fatigue', 'Anxiety', 'Angry',\n",
       "       'Anxiety', 'Normal', 'Anxiety', 'Angry', 'Fatigue', 'Normal',\n",
       "       'Anxiety', 'Happy', 'Fatigue', 'Happy', 'Angry', 'Fatigue',\n",
       "       'Happy'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JrzQKBSxju8"
   },
   "source": [
    "## 3.3 Evaluate and Serialize Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "LTTBiv0ixju8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # Accuracy metrics \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "C5pzliI5xju9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.0\n",
      "rc 0.9967532467532467\n",
      "rf 0.9902597402597403\n",
      "gb 0.9967532467532467\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "gmn8yFphxju9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Anxiety', 'Fatigue', 'Happy', 'Angry', 'Normal', 'Normal',\n",
       "       'Happy', 'Angry', 'Anxiety', 'Happy', 'Fatigue', 'Anxiety',\n",
       "       'Fatigue', 'Normal', 'Fatigue', 'Anxiety', 'Angry', 'Anxiety',\n",
       "       'Normal', 'Angry', 'Fatigue', 'Anxiety', 'Normal', 'Angry',\n",
       "       'Normal', 'Fatigue', 'Anxiety', 'Anxiety', 'Fatigue', 'Happy',\n",
       "       'Normal', 'Anxiety', 'Normal', 'Anxiety', 'Fatigue', 'Fatigue',\n",
       "       'Happy', 'Fatigue', 'Anxiety', 'Anxiety', 'Happy', 'Normal',\n",
       "       'Angry', 'Fatigue', 'Happy', 'Happy', 'Normal', 'Normal',\n",
       "       'Fatigue', 'Normal', 'Fatigue', 'Anxiety', 'Normal', 'Happy',\n",
       "       'Normal', 'Happy', 'Normal', 'Happy', 'Normal', 'Anxiety',\n",
       "       'Normal', 'Normal', 'Happy', 'Anxiety', 'Anxiety', 'Anxiety',\n",
       "       'Angry', 'Happy', 'Angry', 'Normal', 'Fatigue', 'Angry', 'Happy',\n",
       "       'Anxiety', 'Anxiety', 'Anxiety', 'Happy', 'Normal', 'Happy',\n",
       "       'Angry', 'Normal', 'Normal', 'Angry', 'Happy', 'Normal', 'Happy',\n",
       "       'Fatigue', 'Normal', 'Normal', 'Normal', 'Normal', 'Anxiety',\n",
       "       'Angry', 'Fatigue', 'Fatigue', 'Anxiety', 'Anxiety', 'Normal',\n",
       "       'Anxiety', 'Anxiety', 'Anxiety', 'Normal', 'Anxiety', 'Normal',\n",
       "       'Angry', 'Happy', 'Anxiety', 'Fatigue', 'Anxiety', 'Anxiety',\n",
       "       'Angry', 'Fatigue', 'Normal', 'Anxiety', 'Anxiety', 'Anxiety',\n",
       "       'Anxiety', 'Happy', 'Angry', 'Happy', 'Anxiety', 'Angry',\n",
       "       'Fatigue', 'Anxiety', 'Anxiety', 'Happy', 'Happy', 'Fatigue',\n",
       "       'Angry', 'Angry', 'Anxiety', 'Normal', 'Normal', 'Happy',\n",
       "       'Fatigue', 'Fatigue', 'Fatigue', 'Angry', 'Happy', 'Fatigue',\n",
       "       'Angry', 'Anxiety', 'Fatigue', 'Happy', 'Angry', 'Anxiety',\n",
       "       'Normal', 'Fatigue', 'Normal', 'Anxiety', 'Anxiety', 'Happy',\n",
       "       'Happy', 'Angry', 'Angry', 'Anxiety', 'Angry', 'Happy', 'Anxiety',\n",
       "       'Anxiety', 'Happy', 'Angry', 'Happy', 'Happy', 'Angry', 'Angry',\n",
       "       'Happy', 'Anxiety', 'Fatigue', 'Normal', 'Anxiety', 'Normal',\n",
       "       'Normal', 'Angry', 'Fatigue', 'Happy', 'Happy', 'Normal',\n",
       "       'Anxiety', 'Angry', 'Anxiety', 'Angry', 'Anxiety', 'Happy',\n",
       "       'Anxiety', 'Anxiety', 'Fatigue', 'Normal', 'Angry', 'Anxiety',\n",
       "       'Normal', 'Normal', 'Anxiety', 'Anxiety', 'Angry', 'Fatigue',\n",
       "       'Fatigue', 'Fatigue', 'Angry', 'Happy', 'Normal', 'Fatigue',\n",
       "       'Normal', 'Angry', 'Anxiety', 'Fatigue', 'Normal', 'Normal',\n",
       "       'Happy', 'Anxiety', 'Happy', 'Normal', 'Angry', 'Fatigue',\n",
       "       'Fatigue', 'Happy', 'Fatigue', 'Anxiety', 'Happy', 'Happy',\n",
       "       'Angry', 'Normal', 'Happy', 'Normal', 'Happy', 'Angry', 'Anxiety',\n",
       "       'Normal', 'Happy', 'Normal', 'Angry', 'Fatigue', 'Normal', 'Angry',\n",
       "       'Fatigue', 'Fatigue', 'Anxiety', 'Anxiety', 'Normal', 'Anxiety',\n",
       "       'Normal', 'Angry', 'Fatigue', 'Angry', 'Happy', 'Normal',\n",
       "       'Anxiety', 'Happy', 'Fatigue', 'Normal', 'Fatigue', 'Angry',\n",
       "       'Normal', 'Happy', 'Fatigue', 'Normal', 'Fatigue', 'Normal',\n",
       "       'Normal', 'Happy', 'Fatigue', 'Anxiety', 'Anxiety', 'Fatigue',\n",
       "       'Fatigue', 'Anxiety', 'Happy', 'Normal', 'Anxiety', 'Happy',\n",
       "       'Happy', 'Fatigue', 'Happy', 'Happy', 'Normal', 'Normal',\n",
       "       'Fatigue', 'Anxiety', 'Normal', 'Angry', 'Anxiety', 'Fatigue',\n",
       "       'Angry', 'Happy', 'Anxiety', 'Happy', 'Happy', 'Normal', 'Happy',\n",
       "       'Happy', 'Angry', 'Normal', 'Fatigue', 'Anxiety', 'Angry',\n",
       "       'Anxiety', 'Normal', 'Anxiety', 'Angry', 'Fatigue', 'Normal',\n",
       "       'Anxiety', 'Happy', 'Fatigue', 'Happy', 'Angry', 'Fatigue',\n",
       "       'Happy'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "F9TZEalrxju9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "803    Anxiety\n",
       "523    Fatigue\n",
       "89       Happy\n",
       "916      Angry\n",
       "270     Normal\n",
       "        ...   \n",
       "499    Fatigue\n",
       "44       Happy\n",
       "968      Angry\n",
       "504    Fatigue\n",
       "187      Happy\n",
       "Name: class, Length: 308, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "kWNcHCERxju9"
   },
   "outputs": [],
   "source": [
    "with open('body_language1.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szBP27A6xju9"
   },
   "source": [
    "# 4. Make Detections with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "JO1YYSgMxju-"
   },
   "outputs": [],
   "source": [
    "with open('body_language1.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Y4270ulhxju-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "FAqOYVwUxju-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.06 0.4  0.26 0.02 0.26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.09 0.54 0.1  0.04 0.23]\n",
      "Anxiety [0.07 0.73 0.04 0.02 0.14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.06 0.75 0.04 0.01 0.14]\n",
      "Anxiety [0.06 0.76 0.03 0.01 0.14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.06 0.73 0.03 0.01 0.17]\n",
      "Anxiety [0.05 0.72 0.04 0.01 0.18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.04 0.57 0.03 0.   0.36]\n",
      "Anxiety"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0.03 0.5  0.03 0.   0.44]\n",
      "Normal [0.03 0.46 0.04 0.   0.47]\n",
      "Normal"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0.02 0.26 0.08 0.   0.64]\n",
      "Normal [0.04 0.25 0.06 0.   0.65]\n",
      "Normal [0.07 0.25 0.03 0.   0.65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal [0.13 0.4  0.05 0.01 0.41]\n",
      "Anxiety [0.1  0.5  0.06 0.01 0.33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.09 0.49 0.07 0.01 0.34]\n",
      "Anxiety"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0.09 0.57 0.07 0.01 0.26]\n",
      "Anxiety [0.06 0.48 0.07 0.01 0.38]\n",
      "Anxiety [0.05 0.48 0.07 0.   0.4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.03 0.44 0.1  0.   0.43]\n",
      "Normal [0.01 0.35 0.11 0.03 0.5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal [0.01 0.36 0.09 0.01 0.53]\n",
      "Normal [0.01 0.37 0.07 0.   0.55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.01 0.51 0.09 0.   0.39]\n",
      "Anxiety [0.04 0.52 0.04 0.   0.4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal [0.04 0.33 0.01 0.   0.62]\n",
      "Normal [0.03 0.21 0.05 0.   0.71]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal [0.05 0.37 0.05 0.   0.53]\n",
      "Normal [0.03 0.43 0.07 0.   0.47]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.04 0.6  0.06 0.   0.3 ]\n",
      "Anxiety [0.04 0.52 0.06 0.   0.38]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.04 0.5  0.07 0.   0.39]\n",
      "Anxiety [0.05 0.57 0.03 0.   0.35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.06 0.5  0.05 0.   0.39]\n",
      "Anxiety [0.05 0.58 0.08 0.   0.29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.04 0.6  0.09 0.   0.27]\n",
      "Anxiety [0.02 0.62 0.08 0.   0.28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.02 0.58 0.06 0.   0.34]\n",
      "Anxiety [0.02 0.58 0.08 0.   0.32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.03 0.57 0.09 0.01 0.3 ]\n",
      "Anxiety [0.07 0.62 0.03 0.01 0.27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.06 0.67 0.03 0.01 0.23]\n",
      "Anxiety [0.1  0.62 0.02 0.01 0.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.07 0.66 0.02 0.01 0.24]\n",
      "Anxiety [0.09 0.66 0.04 0.02 0.19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.05 0.63 0.1  0.01 0.21]\n",
      "Anxiety [0.06 0.62 0.09 0.01 0.22]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.06 0.63 0.08 0.01 0.22]\n",
      "Anxiety [0.07 0.64 0.07 0.01 0.21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.05 0.64 0.1  0.01 0.2 ]\n",
      "Anxiety [0.09 0.63 0.07 0.01 0.2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.1  0.53 0.09 0.02 0.26]\n",
      "Anxiety [0.1  0.57 0.09 0.01 0.23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.09 0.59 0.11 0.02 0.19]\n",
      "Anxiety"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0.15 0.57 0.09 0.02 0.17]\n",
      "Anxiety [0.11 0.55 0.1  0.02 0.22]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.2  0.55 0.08 0.02 0.15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.29 0.43 0.07 0.03 0.18]\n",
      "Anxiety [0.24 0.55 0.07 0.02 0.12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.2  0.53 0.08 0.03 0.16]\n",
      "Anxiety [0.29 0.46 0.07 0.02 0.16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.18 0.48 0.08 0.03 0.23]\n",
      "Anxiety [0.19 0.5  0.07 0.04 0.2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.12 0.55 0.09 0.02 0.22]\n",
      "Anxiety [0.14 0.58 0.09 0.03 0.16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.1  0.58 0.08 0.02 0.22]\n",
      "Anxiety [0.06 0.61 0.08 0.02 0.23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal [0.02 0.44 0.09 0.   0.45]\n",
      "Anxiety"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0.02 0.51 0.1  0.   0.37]\n",
      "Anxiety [0.01 0.46 0.12 0.   0.41]\n",
      "Normal [0.01 0.44 0.09 0.   0.46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety [0.01 0.46 0.09 0.   0.44]\n",
      "Normal [0.01 0.43 0.08 0.   0.48]\n",
      "Anxiety [0.02 0.47 0.05 0.   0.46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "C:\\Users\\tnahs\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'landmark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-9acea21de53a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m# Extract Face landmarks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mface\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_landmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0mface_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlandmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlandmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlandmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisibility\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlandmark\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mface\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'landmark'"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "       # try:\n",
    "        # Extract Pose landmarks\n",
    "        pose = results.pose_landmarks.landmark\n",
    "        pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "        # Extract Face landmarks\n",
    "        face = results.face_landmarks.landmark\n",
    "        face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "\n",
    "        # Concate rows\n",
    "        row = pose_row+face_row\n",
    "\n",
    "#             # Append class name \n",
    "#             row.insert(0, class_name)\n",
    "\n",
    "#             # Export to CSV\n",
    "#             with open('coords.csv', mode='a', newline='') as f:\n",
    "#                 csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                 csv_writer.writerow(row) \n",
    "\n",
    "        # Make Detections\n",
    "        X = pd.DataFrame([row])\n",
    "        body_language_class = model.predict(X)[0]\n",
    "        body_language_prob = model.predict_proba(X)[0]\n",
    "        print(body_language_class, body_language_prob)\n",
    "\n",
    "        # Grab ear coords\n",
    "        coords = tuple(np.multiply(\n",
    "                        np.array(\n",
    "                            (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                             results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                    , [640,480]).astype(int))\n",
    "\n",
    "        cv2.rectangle(image, \n",
    "                      (coords[0], coords[1]+5), \n",
    "                      (coords[0]+len(body_language_class)*20, coords[1]-30), \n",
    "                      (245, 117, 16), -1)\n",
    "        cv2.putText(image, body_language_class, coords, \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Get status box\n",
    "        cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "\n",
    "        # Display Class\n",
    "        cv2.putText(image, 'CLASS'\n",
    "                    , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, body_language_class.split(' ')[0]\n",
    "                    , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Display Probability\n",
    "        cv2.putText(image, 'PROB'\n",
    "                    , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\n",
    "                    , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "       # except:\n",
    "        #    pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENhWpCSnxju_"
   },
   "outputs": [],
   "source": [
    "tuple(np.multiply(np.array((results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y)), [640,480]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbZnachrxju_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1xySO6sxju_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LsRF8ykxjvA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Body Language Decoder Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
